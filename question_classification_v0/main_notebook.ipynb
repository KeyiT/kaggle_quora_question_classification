{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "281275d20b3c5f659236d880031e3da4b7977e06"
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ebb7ec8cdfe9b840f5b5ba1524f4e892994e46cc",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "713132d2f045501c82e42290550d356ae0727c35",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DATA_ROOT = '../input/'\n",
    "ORIGINAL_DATA_FOLDER = os.path.join(DATA_ROOT, 'movie-review-sentiment-analysis-kernels-only')\n",
    "TMP_DATA_FOLDER = os.path.join(DATA_ROOT, 'kaggle_review_sentiment_tmp_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "98fd884ce5265326d434498bda1f5bb813f24e95",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data_path = os.path.join(ORIGINAL_DATA_FOLDER, 'train.tsv')\n",
    "test_data_path = os.path.join(ORIGINAL_DATA_FOLDER, 'test.tsv')\n",
    "sub_data_path = os.path.join(ORIGINAL_DATA_FOLDER, 'sampleSubmission.csv')\n",
    "\n",
    "train_df = pd.read_csv(train_data_path, sep=\"\\t\")\n",
    "test_df = pd.read_csv(test_data_path, sep=\"\\t\")\n",
    "sub_df = pd.read_csv(sub_data_path, sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ee07dfaceeb2d800b4c95430a5f44d7386fed119"
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "abc33cf6801467c6c8ccd5266961d5e74a70b030"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "33485dab7ac4678cc77fed13b2c8e500d341f72f",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c2e0e484aacbb21ebb2807c79beca5aa054c3830",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "641a74568482c8ad42d1ac1c8982a44b84641166",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c4d3c60c638b8ed36a90102e2f5d0fcb034b9ac4"
   },
   "source": [
    "## Find Overlapped Phrases Between Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "0a31536ca50b348303c4980a7535fdea69716d6e"
   },
   "outputs": [],
   "source": [
    "overlapped = pd.merge(train_df[[\"Phrase\", \"Sentiment\"]], test_df, on=\"Phrase\", how=\"inner\")\n",
    "overlap_boolean_mask_test = test_df['Phrase'].isin(overlapped['Phrase'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2de53b6baefcd985866f4e3789cb923e7c8d57c8"
   },
   "source": [
    "## Histogram of phrase length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "25a101f200f79abef0c91b2fdce721a22ad66b1d"
   },
   "outputs": [],
   "source": [
    "print(\"training data phrase length distribution\")\n",
    "sns.distplot(train_df['Phrase'].map(lambda ele: len(ele)), kde_kws={\"label\": \"train\"})\n",
    "\n",
    "print(\"testing data phrase length distribution\")\n",
    "sns.distplot(test_df[~overlap_boolean_mask_test]['Phrase'].map(lambda ele: len(ele)), kde_kws={\"label\": \"test\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "22c203439a2310d54f0283dc4e117307a1afa82d"
   },
   "source": [
    "## Explore Sentence Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "c957e257b2865c258a6d9ce23b9ed15c316b90b8"
   },
   "outputs": [],
   "source": [
    "print(\"training and testing data sentences hist:\")\n",
    "sns.distplot(train_df['SentenceId'], kde_kws={\"label\": \"train\"})\n",
    "sns.distplot(test_df['SentenceId'], kde_kws={\"label\": \"test\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "6ae6308dd0bb586f7cc6e75619e228f7984116ab"
   },
   "outputs": [],
   "source": [
    "print(\"The number of overlapped SentenceId between training and testing data:\")\n",
    "train_overlapped_sentence_id_df = train_df[train_df['SentenceId'].isin(test_df['SentenceId'])]\n",
    "print(train_overlapped_sentence_id_df.shape[0])\n",
    "\n",
    "del train_overlapped_sentence_id_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "trusted": true,
    "_uuid": "030ab4a34391188a30160731259e21d4611762a2"
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 250\n",
    "print(\"Example of sentence and phrases: \")\n",
    "\n",
    "sample_sentence_id = train_df.sample(1)['SentenceId'].values[0]\n",
    "sample_sentence_group_df = train_df[train_df['SentenceId'] == sample_sentence_id]\n",
    "sample_sentence_group_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "86959890d0944cd3c85201f0107881ae82ce2ad6"
   },
   "source": [
    "1. There are overlapped phrase texts between training and testing data, which should assign training data labels directly instead of getting from prediction.\n2. Max text length should be set around 60.\n3. There is no overlapped sentence between training and testing data. Within each sentence group, the phraseId order is the pre-order tanversal over the dependency parsing tree of the sentence text. (This might be a very important information as we can utilized the composition as powerful predictive information). \n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "09c94783b2b9f99c5d62ea251391642329ec46a6"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f15786c0c632835ae7a008114319badd92dce4c8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import text\n",
    "from keras.preprocessing import sequence\n",
    "import gensim\n",
    "from sklearn import preprocessing as skp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b50c845cca35a18a4f2986d03b37eb826c17e109",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "max_len = 50\n",
    "embed_size = 300\n",
    "max_features = 30000\n",
    "\n",
    "pretrained_w2v_path = os.path.join(DATA_ROOT, \"nlpword2vecembeddingspretrained/GoogleNews-vectors-negative300.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "69e929bce14433c86cda53d35abc91a3b3fd4e72"
   },
   "source": [
    "### Tokenize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f05a0bcf40751a8e33814fd3314b7f7e1d5149e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "full_text = list(train_df['Phrase'].values) + list(test_df[~overlap_boolean_mask_test]['Phrase'].values)\n",
    "\n",
    "tk = text.Tokenizer(lower = True, filters='')\n",
    "tk.fit_on_texts(full_text)\n",
    "train_tokenized = tk.texts_to_sequences(train_df['Phrase'])\n",
    "test_tokenized = tk.texts_to_sequences(test_df[~overlap_boolean_mask_test]['Phrase'])\n",
    "\n",
    "X_train = sequence.pad_sequences(train_tokenized, maxlen = max_len)\n",
    "X_test = sequence.pad_sequences(test_tokenized, maxlen = max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d42d7f7ad3c09838e1648beb5743dbf4e313a543"
   },
   "source": [
    "### Build embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3467eb40c92d5490a26629f6ab6c7505b8439979",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "w2v = gensim.models.KeyedVectors.load_word2vec_format(pretrained_w2v_path, binary=True).wv\n",
    "\n",
    "word_index = tk.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words + 1, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = None\n",
    "    if word in w2v:\n",
    "        embedding_vector = w2v[word]\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "del w2v\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "26e06e8aeabd698b0fe2fb208f2c4ec2855babcd"
   },
   "source": [
    "### Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "57a0df2d2e98b1b1a8edc5ef87dd26f4f1f5d63c",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_train = train_df['Sentiment']\n",
    "\n",
    "led = skp.LabelEncoder()\n",
    "led.fit(y_train.values)\n",
    "\n",
    "y_train = led.transform(y_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4675184968f46ed87fbd703696978dc3535ce89e"
   },
   "source": [
    "# Define Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "391b187f5f79d60fc329dd8a805708ac71937b5b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras import callbacks as kc\n",
    "from keras import optimizers as ko\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras.engine import Layer\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "413a0fcd52787baf4cb702cc1074b8086675b1ba"
   },
   "source": [
    "## Define Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "e59457ba4f41bd4082188ccacff7f1cf8601545c"
   },
   "outputs": [],
   "source": [
    "def _dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatible with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        # todo: check that this is correct\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)\n",
    "    \n",
    "    \n",
    "class AttentionWeight(Layer):\n",
    "    \"\"\"\n",
    "        This code is a modified version of cbaziotis implementation:  GithubGist cbaziotis/AttentionWithContext.py\n",
    "        Attention operation, with a context/query vector, for temporal data.\n",
    "        Supports Masking.\n",
    "        Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
    "        \"Hierarchical Attention Networks for Document Classification\"\n",
    "        by using a context vector to assist the attention\n",
    "        # Input shape\n",
    "            3D tensor with shape: `(samples, steps, features)`.\n",
    "        # Output shape\n",
    "            2D tensor with shape: `(samples, steps)`.\n",
    "        :param kwargs:\n",
    "        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "        The dimensions are inferred based on the output shape of the RNN.\n",
    "        Example:\n",
    "            model.add(LSTM(64, return_sequences=True))\n",
    "            model.add(AttentionWeight())\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(AttentionWeight, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "\n",
    "        self.u = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    "\n",
    "        super(AttentionWeight, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = _dot_product(x, self.W)\n",
    "\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "\n",
    "        uit = K.tanh(uit)\n",
    "        ait = _dot_product(uit, self.u)\n",
    "\n",
    "        a = K.exp(ait)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        return a\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[1]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'W_regularizer': regularizers.serialize(self.W_regularizer),\n",
    "            'u_regularizer': regularizers.serialize(self.u_regularizer),\n",
    "            'b_regularizer': regularizers.serialize(self.b_regularizer),\n",
    "            'W_constraint': constraints.serialize(self.W_constraint),\n",
    "            'u_constraint': constraints.serialize(self.u_constraint),\n",
    "            'b_constraint': constraints.serialize(self.b_constraint),\n",
    "            'bias': self.bias\n",
    "        }\n",
    "        base_config = super(AttentionWeight, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c3e4ae86f2e94275e3bc3de33a5eb9b1f8327caa"
   },
   "source": [
    "## Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "ab6fd1ea52e5cdeb110d5ef79e0cde12b195c586"
   },
   "outputs": [],
   "source": [
    "def is_integer(val):\n",
    "    return isinstance(val, (int, np.int_))\n",
    "\n",
    "def predict(keras_model, x, learning_phase=0):\n",
    "\n",
    "    if isinstance(keras_model.input, list):\n",
    "        f = backend.function(\n",
    "            keras_model.input + [backend.learning_phase()],\n",
    "            [keras_model.output, ]\n",
    "        )\n",
    "        y = f(tuple(x) + (learning_phase,))[0]\n",
    "    else:\n",
    "        f = backend.function(\n",
    "            [keras_model.input, backend.learning_phase()],\n",
    "            [keras_model.output, ]\n",
    "        )\n",
    "        y = f((x, learning_phase))[0]\n",
    "    return y\n",
    "    \n",
    "\n",
    "def build_birnn_attention_model(\n",
    "        voca_dim, time_steps, output_dim, rnn_dim, mlp_dim, \n",
    "        item_embedding=None, rnn_depth=1, mlp_depth=1, num_att_channel=1,\n",
    "        drop_out=0.5, rnn_drop_out=0., rnn_state_drop_out=0.,\n",
    "        trainable_embedding=False, gpu=False, return_customized_layers=False):\n",
    "    \"\"\"\n",
    "    Create A Bidirectional Attention Model.\n",
    "\n",
    "    :param voca_dim: vocabulary dimension size.\n",
    "    :param time_steps: the length of input\n",
    "    :param output_dim: the output dimension size\n",
    "    :param rnn_dim: rrn dimension size\n",
    "    :param mlp_dim: the dimension size of fully connected layer\n",
    "    :param item_embedding: integer, numpy 2D array, or None (default=None)\n",
    "        If item_embedding is a integer, connect a randomly initialized embedding matrix to the input tensor.\n",
    "        If item_embedding is a matrix, this matrix will be used as the embedding matrix.\n",
    "        If item_embedding is None, then connect input tensor to RNN layer directly.\n",
    "    :param rnn_depth: rnn depth\n",
    "    :param mlp_depth: the depth of fully connected layers\n",
    "    :param num_att_channel: the number of attention channels, this can be used to mimic multi-head attention mechanism\n",
    "    :param drop_out: dropout rate of fully connected layers\n",
    "    :param rnn_drop_out: dropout rate of rnn layers\n",
    "    :param rnn_state_drop_out: dropout rate of rnn state tensor\n",
    "    :param trainable_embedding: boolean\n",
    "    :param gpu: boolean, default=False\n",
    "        If True, CuDNNLSTM is used instead of LSTM for RNN layer.\n",
    "    :param return_customized_layers: boolean, default=False\n",
    "        If True, return model and customized object dictionary, otherwise return model only\n",
    "    :return: keras model\n",
    "    \"\"\"\n",
    "    \n",
    "    if item_embedding is not None:\n",
    "        inputs = models.Input(shape=(time_steps,), dtype='int32', name='input0')\n",
    "        x = inputs\n",
    "\n",
    "        # item embedding\n",
    "        if isinstance(item_embedding, np.ndarray):\n",
    "            assert voca_dim == item_embedding.shape[0]\n",
    "            x = layers.Embedding(\n",
    "                voca_dim, item_embedding.shape[1], input_length=time_steps,\n",
    "                weights=[item_embedding, ], trainable=trainable_embedding,\n",
    "                mask_zero=False, name='embedding_layer0'\n",
    "            )(x)\n",
    "        elif utils.is_integer(item_embedding):\n",
    "            x = layers.Embedding(\n",
    "                voca_dim, item_embedding, input_length=time_steps,\n",
    "                trainable=trainable_embedding,\n",
    "                mask_zero=False, name='embedding_layer0'\n",
    "            )(x)\n",
    "        else:\n",
    "            raise ValueError(\"item_embedding must be either integer or numpy matrix\")\n",
    "    else:\n",
    "        inputs = models.Input(shape=(time_steps, voca_dim), dtype='float32', name='input0')\n",
    "        x = inputs\n",
    "    \n",
    "    x = layers.SpatialDropout1D(rnn_drop_out, name='rnn_spatial_droutout_layer')(x)\n",
    "\n",
    "    if gpu:\n",
    "        # rnn encoding\n",
    "        for i in range(rnn_depth):\n",
    "            x = layers.Bidirectional(\n",
    "                layers.CuDNNLSTM(rnn_dim, return_sequences=True),\n",
    "                name='bi_lstm_layer' + str(i))(x)\n",
    "            x = layers.BatchNormalization(name='rnn_batch_norm_layer' + str(i))(x)\n",
    "            x = layers.Dropout(rate=rnn_drop_out, name=\"rnn_dropout_layer\" + str(i))(x)\n",
    "    else:\n",
    "        # rnn encoding\n",
    "        for i in range(rnn_depth):\n",
    "            x = layers.Bidirectional(\n",
    "                layers.LSTM(rnn_dim, return_sequences=True, dropout=rnn_drop_out, recurrent_dropout=rnn_state_drop_out),\n",
    "                name='bi_lstm_layer' + str(i))(x)\n",
    "            x = layers.BatchNormalization(name='rnn_batch_norm_layer' + str(i))(x)\n",
    "\n",
    "    # attention\n",
    "    attention_heads = []\n",
    "    x_per = layers.Permute((2, 1), name='permuted_attention_x')(x)\n",
    "    for h in range(max(1, num_att_channel)):\n",
    "        attention = AttentionWeight(name=\"attention_weights_layer\" + str(h))(x)\n",
    "        xx = layers.Dot([2, 1], name='focus_head' + str(h) + '_layer0')([x_per, attention])\n",
    "        attention_heads.append(xx)\n",
    "\n",
    "    if num_att_channel > 1:\n",
    "        x = layers.Concatenate(name='focus_layer0')(attention_heads)\n",
    "    else:\n",
    "        x = attention_heads[0]\n",
    "\n",
    "    x = layers.BatchNormalization(name='focused_batch_norm_layer')(x)\n",
    "    x = layers.Dropout(rate=rnn_drop_out, name=\"focused_dropout_layer\")(x)\n",
    "\n",
    "    # MLP Layers\n",
    "    for i in range(mlp_depth - 1):\n",
    "        x = layers.Dense(mlp_dim, activation='selu', kernel_initializer='lecun_normal', name='selu_layer' + str(i))(x)\n",
    "        x = layers.AlphaDropout(drop_out, name='alpha_layer' + str(i))(x)\n",
    "\n",
    "    outputs = layers.Dense(output_dim, activation=\"softmax\", name=\"softmax_layer0\")(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "\n",
    "    if return_customized_layers:\n",
    "        return model, {'AttentionWeight': AttentionWeight}\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_cnn_model(\n",
    "        voca_dim, time_steps, output_dim, mlp_dim, num_filters, filter_sizes,\n",
    "        item_embedding=None, mlp_depth=1,\n",
    "        drop_out=0.5, cnn_drop_out=0.5, pooling='max', padding='valid',\n",
    "        trainable_embedding=False, return_customized_layers=False):\n",
    "    \"\"\"\n",
    "    Create A CNN Model.\n",
    "\n",
    "    :param voca_dim: vocabulary dimension size.\n",
    "    :param time_steps: the length of input\n",
    "    :param output_dim: the output dimension size\n",
    "    :param num_filters: list of integers\n",
    "        The number of filters.\n",
    "    :param filter_sizes: list of integers\n",
    "        The kernel size.\n",
    "    :param mlp_dim: the dimension size of fully connected layer\n",
    "    :param item_embedding: integer, numpy 2D array, or None (default=None)\n",
    "        If item_embedding is a integer, connect a randomly initialized embedding matrix to the input tensor.\n",
    "        If item_embedding is a matrix, this matrix will be used as the embedding matrix.\n",
    "        If item_embedding is None, then connect input tensor to RNN layer directly.\n",
    "    :param mlp_depth: the depth of fully connected layers\n",
    "    :param drop_out: dropout rate of fully connected layers\n",
    "    :param cnn_drop_out: dropout rate of between cnn layer and fully connected layers\n",
    "    :param pooling: str, either 'max' or 'average'\n",
    "        Pooling method.\n",
    "    :param padding: One of \"valid\", \"causal\" or \"same\" (case-insensitive).\n",
    "        Padding method.\n",
    "    :param trainable_embedding: boolean\n",
    "    :param return_customized_layers: boolean, default=False\n",
    "        If True, return model and customized object dictionary, otherwise return model only\n",
    "    :return: keras model\n",
    "    \"\"\"\n",
    "\n",
    "    if item_embedding is not None:\n",
    "        inputs = models.Input(shape=(time_steps,), dtype='int32', name='input0')\n",
    "        x = inputs\n",
    "\n",
    "        # item embedding\n",
    "        if isinstance(item_embedding, np.ndarray):\n",
    "            assert voca_dim == item_embedding.shape[0]\n",
    "            x = layers.Embedding(\n",
    "                voca_dim, item_embedding.shape[1], input_length=time_steps,\n",
    "                weights=[item_embedding, ], trainable=trainable_embedding,\n",
    "                mask_zero=False, name='embedding_layer0'\n",
    "            )(x)\n",
    "        elif utils.is_integer(item_embedding):\n",
    "            x = layers.Embedding(\n",
    "                voca_dim, item_embedding, input_length=time_steps,\n",
    "                trainable=trainable_embedding,\n",
    "                mask_zero=False, name='embedding_layer0'\n",
    "            )(x)\n",
    "        else:\n",
    "            raise ValueError(\"item_embedding must be either integer or numpy matrix\")\n",
    "    else:\n",
    "        inputs = models.Input(shape=(time_steps, voca_dim), dtype='float32', name='input0')\n",
    "        x = inputs\n",
    "    \n",
    "    x = layers.SpatialDropout1D(cnn_drop_out, name='cnn_spatial_droutout_layer')(x)\n",
    "\n",
    "    pooled_outputs = []\n",
    "    for i in range(len(filter_sizes)):\n",
    "        conv = layers.Conv1D(num_filters[i], kernel_size=filter_sizes[i], padding=padding, activation='relu')(x)\n",
    "        if pooling == 'max':\n",
    "            conv = layers.GlobalMaxPooling1D(name='global_pooling_layer' + str(i))(conv)\n",
    "        else:\n",
    "            conv = layers.GlobalAveragePooling1D(name='global_pooling_layer' + str(i))(conv)\n",
    "        pooled_outputs.append(conv)\n",
    "\n",
    "    x = layers.Concatenate(name='concated_layer')(pooled_outputs)\n",
    "    x = layers.Dropout(cnn_drop_out, name='conv_dropout_layer')(x)\n",
    "    x = layers.BatchNormalization(name=\"batch_norm_layer\")(x)\n",
    "\n",
    "    # MLP Layers\n",
    "    for i in range(mlp_depth - 1):\n",
    "        x = layers.Dense(mlp_dim, activation='selu', kernel_initializer='lecun_normal', name='selu_layer' + str(i))(x)\n",
    "        x = layers.AlphaDropout(drop_out, name='alpha_layer' + str(i))(x)\n",
    "\n",
    "    outputs = layers.Dense(output_dim, activation=\"softmax\", name=\"softmax_layer0\")(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "\n",
    "    if return_customized_layers:\n",
    "        return model, dict()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_birnn_cnn_model(\n",
    "        voca_dim, time_steps, output_dim, rnn_dim, mlp_dim, num_filters, filter_sizes,\n",
    "        item_embedding=None, rnn_depth=1, mlp_depth=1,\n",
    "        drop_out=0.5, rnn_drop_out=0.5, rnn_state_drop_out=0.5, cnn_drop_out=0.5, pooling='max', padding='valid',\n",
    "        trainable_embedding=False, gpu=False, return_customized_layers=False):\n",
    "    \"\"\"\n",
    "    Create A Bidirectional CNN Model.\n",
    "\n",
    "    :param voca_dim: vocabulary dimension size.\n",
    "    :param time_steps: the length of input\n",
    "    :param output_dim: the output dimension size\n",
    "    :param rnn_dim: rrn dimension size\n",
    "    :param num_filters: list of integers\n",
    "        The number of filters.\n",
    "    :param filter_sizes: list of integers\n",
    "        The kernel size.\n",
    "    :param mlp_dim: the dimension size of fully connected layer\n",
    "    :param item_embedding: integer, numpy 2D array, or None (default=None)\n",
    "        If item_embedding is a integer, connect a randomly initialized embedding matrix to the input tensor.\n",
    "        If item_embedding is a matrix, this matrix will be used as the embedding matrix.\n",
    "        If item_embedding is None, then connect input tensor to RNN layer directly.\n",
    "    :param rnn_depth: rnn depth\n",
    "    :param mlp_depth: the depth of fully connected layers\n",
    "    :param num_att_channel: the number of attention channels, this can be used to mimic multi-head attention mechanism\n",
    "    :param drop_out: dropout rate of fully connected layers\n",
    "    :param rnn_drop_out: dropout rate of rnn layers\n",
    "    :param rnn_state_drop_out: dropout rate of rnn state tensor\n",
    "    :param cnn_drop_out: dropout rate of between cnn layer and fully connected layers\n",
    "    :param pooling: str, either 'max' or 'average'\n",
    "        Pooling method.\n",
    "    :param padding: One of \"valid\", \"causal\" or \"same\" (case-insensitive).\n",
    "        Padding method.\n",
    "    :param trainable_embedding: boolean\n",
    "    :param gpu: boolean, default=False\n",
    "        If True, CuDNNLSTM is used instead of LSTM for RNN layer.\n",
    "    :param return_customized_layers: boolean, default=False\n",
    "        If True, return model and customized object dictionary, otherwise return model only\n",
    "    :return: keras model\n",
    "    \"\"\"\n",
    "\n",
    "    if item_embedding is not None:\n",
    "        inputs = models.Input(shape=(time_steps,), dtype='int32', name='input0')\n",
    "        x = inputs\n",
    "\n",
    "        # item embedding\n",
    "        if isinstance(item_embedding, np.ndarray):\n",
    "            assert voca_dim == item_embedding.shape[0]\n",
    "            x = layers.Embedding(\n",
    "                voca_dim, item_embedding.shape[1], input_length=time_steps,\n",
    "                weights=[item_embedding, ], trainable=trainable_embedding,\n",
    "                mask_zero=False, name='embedding_layer0'\n",
    "            )(x)\n",
    "        elif utils.is_integer(item_embedding):\n",
    "            x = layers.Embedding(\n",
    "                voca_dim, item_embedding, input_length=time_steps,\n",
    "                trainable=trainable_embedding,\n",
    "                mask_zero=False, name='embedding_layer0'\n",
    "            )(x)\n",
    "        else:\n",
    "            raise ValueError(\"item_embedding must be either integer or numpy matrix\")\n",
    "    else:\n",
    "        inputs = models.Input(shape=(time_steps, voca_dim), dtype='float32', name='input0')\n",
    "        x = inputs\n",
    "        \n",
    "    x = layers.SpatialDropout1D(rnn_drop_out, name='rnn_spatial_droutout_layer')(x)\n",
    "\n",
    "    if gpu:\n",
    "        # rnn encoding\n",
    "        for i in range(rnn_depth):\n",
    "            x = layers.Bidirectional(\n",
    "                layers.CuDNNLSTM(rnn_dim, return_sequences=True),\n",
    "                name='bi_lstm_layer' + str(i))(x)\n",
    "            x = layers.BatchNormalization(name='rnn_batch_norm_layer' + str(i))(x)\n",
    "            x = layers.Dropout(rate=rnn_drop_out, name=\"rnn_dropout_layer\" + str(i))(x)\n",
    "    else:\n",
    "        # rnn encoding\n",
    "        for i in range(rnn_depth):\n",
    "            x = layers.Bidirectional(\n",
    "                layers.LSTM(rnn_dim, return_sequences=True, dropout=rnn_drop_out, recurrent_dropout=rnn_state_drop_out),\n",
    "                name='bi_lstm_layer' + str(i))(x)\n",
    "            x = layers.BatchNormalization(name='rnn_batch_norm_layer' + str(i))(x)\n",
    "\n",
    "    pooled_outputs = []\n",
    "    for i in range(len(filter_sizes)):\n",
    "        conv = layers.Conv1D(num_filters[i], kernel_size=filter_sizes[i], padding=padding, activation='relu')(x)\n",
    "        if pooling == 'max':\n",
    "            conv = layers.GlobalMaxPooling1D(name='global_pooling_layer' + str(i))(conv)\n",
    "        else:\n",
    "            conv = layers.GlobalAveragePooling1D(name='global_pooling_layer' + str(i))(conv)\n",
    "        pooled_outputs.append(conv)\n",
    "\n",
    "    x = layers.Concatenate(name='concated_layer')(pooled_outputs)\n",
    "    x = layers.BatchNormalization(name=\"batch_norm_layer\")(x)\n",
    "    x = layers.Dropout(cnn_drop_out, name='conv_dropout_layer')(x)\n",
    "\n",
    "    # MLP Layers\n",
    "    for i in range(mlp_depth - 1):\n",
    "        x = layers.Dense(mlp_dim, activation='selu', kernel_initializer='lecun_normal', name='selu_layer' + str(i))(x)\n",
    "        x = layers.AlphaDropout(drop_out, name='alpha_layer' + str(i))(x)\n",
    "\n",
    "    outputs = layers.Dense(output_dim, activation=\"softmax\", name=\"softmax_layer0\")(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "\n",
    "    if return_customized_layers:\n",
    "        return model, dict()\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_birnn_hierarchy_cnn_model(\n",
    "        voca_dim, time_steps, output_dim, rnn_dim, mlp_dim, num_filters, filter_sizes, \n",
    "        dilation_rates=1, strides=1,\n",
    "        item_embedding=None, rnn_depth=1, mlp_depth=1,\n",
    "        drop_out=0.5, rnn_drop_out=0.5, rnn_state_drop_out=0.5, cnn_drop_out=0.5, pooling='max', padding='valid',\n",
    "        trainable_embedding=False, gpu=False, return_customized_layers=False):\n",
    "    \"\"\"\n",
    "    Create A Bidirectional CNN Model.\n",
    "\n",
    "    :param voca_dim: vocabulary dimension size.\n",
    "    :param time_steps: the length of input\n",
    "    :param output_dim: the output dimension size\n",
    "    :param rnn_dim: rrn dimension size\n",
    "    :param num_filters: list of integers\n",
    "        The number of filters.\n",
    "    :param filter_sizes: list of integers\n",
    "        The kernel size.\n",
    "    :param mlp_dim: the dimension size of fully connected layer\n",
    "    :param item_embedding: integer, numpy 2D array, or None (default=None)\n",
    "        If item_embedding is a integer, connect a randomly initialized embedding matrix to the input tensor.\n",
    "        If item_embedding is a matrix, this matrix will be used as the embedding matrix.\n",
    "        If item_embedding is None, then connect input tensor to RNN layer directly.\n",
    "    :param rnn_depth: rnn depth\n",
    "    :param mlp_depth: the depth of fully connected layers\n",
    "    :param num_att_channel: the number of attention channels, this can be used to mimic multi-head attention mechanism\n",
    "    :param drop_out: dropout rate of fully connected layers\n",
    "    :param rnn_drop_out: dropout rate of rnn layers\n",
    "    :param rnn_state_drop_out: dropout rate of rnn state tensor\n",
    "    :param cnn_drop_out: dropout rate of between cnn layer and fully connected layers\n",
    "    :param pooling: str, either 'max' or 'average'\n",
    "        Pooling method.\n",
    "    :param padding: One of \"valid\", \"causal\" or \"same\" (case-insensitive).\n",
    "        Padding method.\n",
    "    :param trainable_embedding: boolean\n",
    "    :param gpu: boolean, default=False\n",
    "        If True, CuDNNLSTM is used instead of LSTM for RNN layer.\n",
    "    :param return_customized_layers: boolean, default=False\n",
    "        If True, return model and customized object dictionary, otherwise return model only\n",
    "    :return: keras model\n",
    "    \"\"\"\n",
    "\n",
    "    if item_embedding is not None:\n",
    "        inputs = models.Input(shape=(time_steps,), dtype='int32', name='input0')\n",
    "        x = inputs\n",
    "\n",
    "        # item embedding\n",
    "        if isinstance(item_embedding, np.ndarray):\n",
    "            assert voca_dim == item_embedding.shape[0]\n",
    "            x = layers.Embedding(\n",
    "                voca_dim, item_embedding.shape[1], input_length=time_steps,\n",
    "                weights=[item_embedding, ], trainable=trainable_embedding,\n",
    "                mask_zero=False, name='embedding_layer0'\n",
    "            )(x)\n",
    "        elif utils.is_integer(item_embedding):\n",
    "            x = layers.Embedding(\n",
    "                voca_dim, item_embedding, input_length=time_steps,\n",
    "                trainable=trainable_embedding,\n",
    "                mask_zero=False, name='embedding_layer0'\n",
    "            )(x)\n",
    "        else:\n",
    "            raise ValueError(\"item_embedding must be either integer or numpy matrix\")\n",
    "    else:\n",
    "        inputs = models.Input(shape=(time_steps, voca_dim), dtype='float32', name='input0')\n",
    "        x = inputs\n",
    "        \n",
    "    x = layers.SpatialDropout1D(rnn_drop_out, name='rnn_spatial_droutout_layer')(x)\n",
    "\n",
    "    if gpu:\n",
    "        # rnn encoding\n",
    "        for i in range(rnn_depth):\n",
    "            x = layers.Bidirectional(\n",
    "                layers.CuDNNLSTM(rnn_dim, return_sequences=True),\n",
    "                name='bi_lstm_layer' + str(i))(x)\n",
    "            x = layers.BatchNormalization(name='rnn_batch_norm_layer' + str(i))(x)\n",
    "            x = layers.Dropout(rate=rnn_drop_out, name=\"rnn_dropout_layer\" + str(i))(x)\n",
    "    else:\n",
    "        # rnn encoding\n",
    "        for i in range(rnn_depth):\n",
    "            x = layers.Bidirectional(\n",
    "                layers.LSTM(rnn_dim, return_sequences=True, dropout=rnn_drop_out, recurrent_dropout=rnn_state_drop_out),\n",
    "                name='bi_lstm_layer' + str(i))(x)\n",
    "            x = layers.BatchNormalization(name='rnn_batch_norm_layer' + str(i))(x)\n",
    "\n",
    "    for i in range(len(filter_sizes)):\n",
    "        if is_integer(dilation_rates):\n",
    "            di_rate = dilation_rates\n",
    "        else:\n",
    "            di_rate = dilation_rates[i]\n",
    "        \n",
    "        if is_integer(strides):\n",
    "            std = strides\n",
    "        else:\n",
    "            std = strides[i]\n",
    "            \n",
    "        x = layers.Conv1D(num_filters[i], kernel_size=filter_sizes[i], padding=padding, activation='relu', dilation_rate=di_rate, strides=std)(x)\n",
    "        \n",
    "    if pooling == 'max':\n",
    "        x = layers.GlobalMaxPooling1D(name='global_pooling_layer')(x)\n",
    "    else:\n",
    "        x = layers.GlobalAveragePooling1D(name='global_pooling_layer')(x)\n",
    "\n",
    "    x = layers.BatchNormalization(name=\"batch_norm_layer\")(x)\n",
    "    x = layers.Dropout(cnn_drop_out, name='conv_dropout_layer')(x)\n",
    "\n",
    "    # MLP Layers\n",
    "    for i in range(mlp_depth - 1):\n",
    "        x = layers.Dense(mlp_dim, activation='selu', kernel_initializer='lecun_normal', name='selu_layer' + str(i))(x)\n",
    "        x = layers.AlphaDropout(drop_out, name='alpha_layer' + str(i))(x)\n",
    "\n",
    "    outputs = layers.Dense(output_dim, activation=\"softmax\", name=\"softmax_layer0\")(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "\n",
    "    if return_customized_layers:\n",
    "        return model, dict()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0f8a54b45eb4838d7459e6db57e9f0a95bfe7e60"
   },
   "source": [
    "# Build and Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "9dd9a276408dd3543d44e4e82cd8086024f56b3f"
   },
   "outputs": [],
   "source": [
    "from keras.utils import model_to_dot\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "83515918a1861d9aa3ef7751aaf05ca1635d9620"
   },
   "outputs": [],
   "source": [
    "histories = list()\n",
    "iterations = list()\n",
    "model_builders = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d514af1525ce6dd02614bfdc4c1c707617eceade"
   },
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9fcdab9f1bfb6d88b2e3d110dea35f87c71dbf51",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_model1():\n",
    "    voca_dim = embedding_matrix.shape[0]\n",
    "    time_steps = max_len\n",
    "    output_dim = led.classes_.shape[0]\n",
    "    mlp_dim = 50\n",
    "    num_filters = [128, 128, 128]\n",
    "    filter_sizes = [1, 3, 5]\n",
    "    item_embedding = embedding_matrix\n",
    "    mlp_depth = 2\n",
    "    cnn_drop_out = 0.2\n",
    "    mlp_drop_out = 0.2\n",
    "    padding = 'causal'\n",
    "\n",
    "    return build_cnn_model(\n",
    "        voca_dim, time_steps, output_dim, mlp_dim, num_filters, filter_sizes, \n",
    "        item_embedding=item_embedding, mlp_depth=2, cnn_drop_out=cnn_drop_out,\n",
    "        padding=padding,\n",
    "        return_customized_layers=True\n",
    "    )\n",
    "\n",
    "model_builders.append(build_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f5e58b1f129140130e4559b1610c307d50f15f8d",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model, cnn_cl = build_model1()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "82b16272ecfe86ee0dc3e5731d4e33aa016842c3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "adam = ko.Nadam()\n",
    "model.compile(adam, loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\",])\n",
    "\n",
    "file_path = \"best_cnn_model.hdf5\"\n",
    "check_point = kc.ModelCheckpoint(file_path, monitor = \"val_sparse_categorical_accuracy\", verbose = 1, save_best_only = True, mode = \"max\")\n",
    "early_stop = kc.EarlyStopping(monitor = \"val_sparse_categorical_accuracy\", mode = \"max\", patience=3)\n",
    "history = model.fit(X_train, y_train, batch_size=500, epochs=20, validation_split=0.1, callbacks = [check_point, early_stop])\n",
    "\n",
    "histories.append(np.max(np.asarray(history.history['val_sparse_categorical_accuracy'])))\n",
    "iterations.append(np.argmax(np.asarray(history.history['val_sparse_categorical_accuracy'])))\n",
    "del model, history\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "db9ac105bd787c06a1371eaf61936b1159c1645c"
   },
   "source": [
    "## Attention RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "46d854b13ad591f5d349af3007a0b17559f72535",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_model2():\n",
    "    voca_dim = embedding_matrix.shape[0]\n",
    "    time_steps = max_len\n",
    "    output_dim = led.classes_.shape[0]\n",
    "    rnn_dim = 100\n",
    "    mlp_dim = 50\n",
    "    item_embedding = embedding_matrix\n",
    "    rnn_depth=1\n",
    "    mlp_depth = 2\n",
    "    rnn_drop_out = 0.3\n",
    "    rnn_state_drop_out = 0.3\n",
    "    mlp_drop_out = 0.2\n",
    "    num_att_channel = 1\n",
    "    gpu=True\n",
    "    \n",
    "    return build_birnn_attention_model(\n",
    "        voca_dim, time_steps, output_dim, rnn_dim, mlp_dim, \n",
    "        item_embedding=item_embedding, rnn_depth=rnn_depth, mlp_depth=mlp_depth, num_att_channel=num_att_channel,\n",
    "        rnn_drop_out=rnn_drop_out, rnn_state_drop_out=rnn_state_drop_out,\n",
    "        gpu=gpu, return_customized_layers=True\n",
    "    )\n",
    "\n",
    "model_builders.append(build_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2a264d510a763478c67b572c14366ae2144ce3f8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model, rnn_cl = build_model2()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d40857a43116f8587f28ba89baef17b519c58d45",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "adam = ko.Nadam(clipnorm=2.0)\n",
    "model.compile(adam, loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\",])\n",
    "\n",
    "file_path = \"best_birnn_attention_model.hdf5\"\n",
    "check_point = kc.ModelCheckpoint(file_path, monitor = \"val_sparse_categorical_accuracy\", verbose = 1, save_best_only = True, mode = \"max\")\n",
    "early_stop = kc.EarlyStopping(monitor = \"val_sparse_categorical_accuracy\", mode = \"max\", patience=3)\n",
    "history = model.fit(X_train, y_train, batch_size=500, epochs=20, validation_split=0.1, callbacks = [check_point, early_stop])\n",
    "\n",
    "histories.append(np.max(np.asarray(history.history['val_sparse_categorical_accuracy'])))\n",
    "iterations.append(np.argmax(np.asarray(history.history['val_sparse_categorical_accuracy'])))\n",
    "del model, history\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e53b77f6a8507bc64a2de060a1718366ee24200f"
   },
   "source": [
    "## RNN-CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1a3294e306d5ac35c0bf0fa039fc17099a83f367",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_model3():\n",
    "    voca_dim = embedding_matrix.shape[0]\n",
    "    time_steps = max_len\n",
    "    output_dim = led.classes_.shape[0]\n",
    "    rnn_dim = 100\n",
    "    mlp_dim = 50\n",
    "    item_embedding = embedding_matrix\n",
    "    rnn_depth=1\n",
    "    mlp_depth = 2\n",
    "    num_filters = [128, 128, 128]\n",
    "    filter_sizes = [1, 3, 5]\n",
    "    cnn_drop_out = 0.2\n",
    "    rnn_drop_out = 0.3\n",
    "    rnn_state_drop_out = 0.3\n",
    "    mlp_drop_out = 0.2\n",
    "    padding = 'causal'\n",
    "    gpu=True\n",
    "    \n",
    "    return build_birnn_cnn_model(\n",
    "        voca_dim, time_steps, output_dim, rnn_dim, mlp_dim, num_filters, filter_sizes, \n",
    "        item_embedding=item_embedding, rnn_depth=rnn_depth, mlp_depth=mlp_depth,\n",
    "        rnn_drop_out=rnn_drop_out, rnn_state_drop_out=rnn_state_drop_out, cnn_drop_out=cnn_drop_out,\n",
    "        padding=padding,\n",
    "        gpu=gpu, return_customized_layers=True\n",
    "    )\n",
    "\n",
    "model_builders.append(build_model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c9e49dcf31d32f1b4717a3ccf665aacad1a1e165",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model, rc_cl = build_model3()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "39f08fded4a3019dfd07504da932064425f8a16b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "adam = ko.Nadam(clipnorm=2.0)\n",
    "model.compile(adam, loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\",])\n",
    "\n",
    "file_path = \"best_birnn_cnn_model.hdf5\"\n",
    "check_point = kc.ModelCheckpoint(file_path, monitor = \"val_sparse_categorical_accuracy\", verbose = 1, save_best_only = True, mode = \"max\")\n",
    "early_stop = kc.EarlyStopping(monitor = \"val_sparse_categorical_accuracy\", mode = \"max\", patience=3)\n",
    "history = model.fit(X_train, y_train, batch_size=500, epochs=20, validation_split=0.1, callbacks = [check_point, early_stop])\n",
    "\n",
    "histories.append(np.max(np.asarray(history.history['val_sparse_categorical_accuracy'])))\n",
    "iterations.append(np.argmax(np.asarray(history.history['val_sparse_categorical_accuracy'])))\n",
    "del model, history\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b4165b5741a971bb4a651a9d513ee2e1d3c19aa5"
   },
   "source": [
    "## RNN-HierarchyCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "0ee00f133652fa813b55f4f223b87beddb588bcf"
   },
   "outputs": [],
   "source": [
    "def build_model4():\n",
    "    voca_dim = embedding_matrix.shape[0]\n",
    "    time_steps = max_len\n",
    "    output_dim = led.classes_.shape[0]\n",
    "    rnn_dim = 100\n",
    "    mlp_dim = 50\n",
    "    item_embedding = embedding_matrix\n",
    "    rnn_depth=1\n",
    "    mlp_depth = 2\n",
    "    num_filters = [128, 256, 512]\n",
    "    filter_sizes = [1, 3, 5]\n",
    "    dilation_rates = [1, 2, 4]\n",
    "    strides=1\n",
    "    cnn_drop_out = 0.2\n",
    "    rnn_drop_out = 0.3\n",
    "    rnn_state_drop_out = 0.3\n",
    "    mlp_drop_out = 0.2\n",
    "    padding = 'causal'\n",
    "    gpu=True\n",
    "    \n",
    "    return build_birnn_hierarchy_cnn_model(\n",
    "        voca_dim, time_steps, output_dim, rnn_dim, mlp_dim, num_filters, filter_sizes, \n",
    "        dilation_rates=dilation_rates, strides=strides,\n",
    "        item_embedding=item_embedding, rnn_depth=rnn_depth, mlp_depth=mlp_depth,\n",
    "        rnn_drop_out=rnn_drop_out, rnn_state_drop_out=rnn_state_drop_out, cnn_drop_out=cnn_drop_out,\n",
    "        padding=padding,\n",
    "        gpu=gpu, return_customized_layers=True\n",
    "    )\n",
    "\n",
    "model_builders.append(build_model4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "d85a1e00009b635853e8928c83b3733a32f37d48"
   },
   "outputs": [],
   "source": [
    "model, rhc_cl = build_model4()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "276d7133a37091457cdead0efb311ce01e20f689"
   },
   "outputs": [],
   "source": [
    "adam = ko.Nadam(clipnorm=2.0)\n",
    "model.compile(adam, loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\",])\n",
    "\n",
    "file_path = \"best_birnn_hierarchy_cnn_model.hdf5\"\n",
    "check_point = kc.ModelCheckpoint(file_path, monitor = \"val_sparse_categorical_accuracy\", verbose = 1, save_best_only = True, mode = \"max\")\n",
    "early_stop = kc.EarlyStopping(monitor = \"val_sparse_categorical_accuracy\", mode = \"max\", patience=3)\n",
    "history = model.fit(X_train, y_train, batch_size=500, epochs=20, validation_split=0.1, callbacks = [check_point, early_stop])\n",
    "\n",
    "histories.append(np.max(np.asarray(history.history['val_sparse_categorical_accuracy'])))\n",
    "iterations.append(np.argmax(np.asarray(history.history['val_sparse_categorical_accuracy'])))\n",
    "del model, history\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "db9a896a94311439b6eda66aa247e828fb57eca2"
   },
   "source": [
    "# Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "428880b633b909db6d5056d4751ce3dabc9fd1a5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "histories = np.asarray(histories)\n",
    "\n",
    "model_paths = [\n",
    "    \"best_cnn_model.hdf5\",\n",
    "    \"best_birnn_attention_model.hdf5\",\n",
    "    \"best_birnn_cnn_model.hdf5\",\n",
    "    \"best_birnn_hierarchy_cnn_model.hdf5\"\n",
    "]\n",
    "\n",
    "cls =[\n",
    "    cnn_cl, rnn_cl, rc_cl, rhc_cl\n",
    "]\n",
    "\n",
    "pred = list()\n",
    "for idx in range(len(model_paths)):\n",
    "    model = models.load_model(model_paths[idx], cls[idx])\n",
    "    pred_tmp = model.predict(X_test, batch_size = 1024, verbose = 1)\n",
    "    pred.append(np.round(np.argmax(pred_tmp, axis=1)).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3ef083a0a29b808560344a0d52d1fb5a77a3a2da",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pred = [\n",
    "    np.asarray([1, 2, 3, 4]),\n",
    "    np.asarray([0, 3, 5, 5]),\n",
    "    np.asarray([1, 2, 2, 4])\n",
    "]\n",
    "\n",
    "def majority_vote(preds_data_point):\n",
    "    unique, counts = np.unique(preds_data_point, return_counts=True)\n",
    "    idx = np.argmax(counts)\n",
    "    return unique[idx]\n",
    "\n",
    "pred = np.asarray(pred)\n",
    "predictions = list()\n",
    "for i in range(pred.shape[1]):\n",
    "    predictions.append(majority_vote(pred[:, i]))\n",
    "predictions = np.asarray(predictions)\n",
    "\n",
    "test_not_overlap_df = test_df[~overlap_boolean_mask_test]\n",
    "test_not_overlap_df['Sentiment'] = predictions\n",
    "\n",
    "res_df = pd.concat([overlapped, test_not_overlap_df], sort=True)[sub_df.columns.values.tolist()]\n",
    "\n",
    "assert sub_df.shape[0] == res_df.shape[0]\n",
    "assert sub_df.shape[1] == res_df.shape[1]\n",
    "\n",
    "res_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
